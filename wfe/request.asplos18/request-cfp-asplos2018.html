<!-- copied from ck-quest repo! -->

<!---------------------------------------------------------------------------------------->
<center>
<!-- <h2>ReQuEST&nbsp;@&nbsp;ASPLOS'18</h2> -->
<h2>1st Reproducible Tournament on Pareto-efficient Image Classification</h2>

 <i>
  We bring together multidisciplinary researchers
  (AI, ML, systems) to find the most efficient and reproducible 
  solutions for realistic problems requested by our advisory board
  in terms of speed, accuracy, energy, complexity, costs and other metrics
  across the whole application/software/hardware stack from IoT to supercomputers!

  All the winning solutions (code, data, workflow) on a Pareto-frontier are then available 
  to the community as portable, customizable and optimized "plug&play" AI/ML blocks
  with a common API to accelerate innovation and adoption of AI/ML by academia and industry!
 </i>

<p>
The associated ACM ReQuEST workshop is co-located with <a href="https://www.asplos2018.org">ASPLOS 2018</a><br>
March 24th, 2018 (afternoon), Williamsburg, VA, USA.

<p>
A ReQuEST introduction and long-term goals: <a href="$#ck_root_page_url#$request$#ck_page_suffix#$">cKnowledge.org/request</a>


<!---------------------------------------------------------------------------------------->

<div id="ck_menu2">
 <div style="background-color:#e5e5FF;padding:5px;margin:5px">
  <center>
   <a href="#program"><b>Final program</b></a>
   &nbsp;&nbsp;&nbsp;
   <a href="#panel"><b>Discussion panel</b></a>
   &nbsp;&nbsp;&nbsp;
   <a href="#important_dates">Important dates</a>
   &nbsp;&nbsp;&nbsp;
   <a href="#call">Call for submissions</a>
   &nbsp;&nbsp;&nbsp;
   <a href="#organizers">Organizers</a>
   &nbsp;&nbsp;&nbsp;
   <a href="#industrial_board">Industrial board</a>
  </center>
 </div>
</div>

 <a href="http://acm.org"><img src="$#ck_url_template_pull#$_resources/logo_acm_resized.jpg" style="padding:10px;" width="75" /></a>
 <a href="http://sigarch.org"><img src="$#ck_url_template_pull#$_resources/logo-sigarch.png" style="padding:10px;" width="180" /></a>
 <a href="https://www.cornell.edu"><img src="$#ck_url_template_pull#$_resources/logo-cornell-university3.png" style="padding:10px;" width="70" /></a>
 <a href="https://www.washington.edu"><img src="$#ck_url_template_pull#$_resources/logo-university-of-washington2.png" style="padding:10px;" width="200"/></a>
 <a href="https://www.cam.ac.uk"><img src="$#ck_url_template_pull#$_resources/logo-university-of-cambridge2.png" style="padding:10px;" width="70" /></a>
 <a href="https://www.epfl.ch"><img src="$#ck_url_template_pull#$_resources/logo-epfl2.png" style="padding:10px;" width="140"/></a>
 <a href="https://www.utoronto.ca/"><img src="$#ck_url_template_pull#$_resources/logo-university-of-toronto2.png" style="padding:10px;" width="160"/></a>
 <a href="http://dividiti.com"><img src="$#ck_url_template_pull#$_resources/logo_dvdt_500.png" style="padding:10px;"  width="35"/></a>
 <a href="http://cTuning.org"><img src="$#ck_url_template_pull#$_resources/CTuning_foundation_logo3.png" style="padding:10px;"  width="110"/></a>

<a id="organizers">
<div style="padding:10px;">

 <div style="width:500px;padding:10px;margin:10px;background-color:#FFFFDF;text-align:left;display:inline-block;">
  <h3>Organizers (A-Z)</h3>

  <ul>
   <li><a href="https://www.cs.washington.edu/people/faculty/luisceze">Luis Ceze</a>, University of Washington, USA
   <li><a href="http://www.eecg.toronto.edu/~enright">Natalie Enright Jerger</a>, University of Toronto, Canada
   <li><a href="https://parsa.epfl.ch/~falsafi">Babak Falsafi</a>, EPFL, Switzerland
   <li><a href="http://fursin.net/research.html">Grigori Fursin</a>, cTuning foundation, France <i>(artifact evaluation & framework)</i>
   <li><a href="https://uk.linkedin.com/in/lokhmotov">Anton Lokhmotov</a>, dividiti, UK <i>(industrial relations)</i>
   <li><a href="https://homes.cs.washington.edu/~moreau">Thierry Moreau</a>, University of Washington, USA <i>(workshop organization)</i>
   <li><a href="http://www.cs.cornell.edu/~asampson">Adrian Sampson</a>, Cornell University, USA
   <li><a href="https://www.energy.cam.ac.uk/directory/ps751@cam.ac.uk">Phillip Stanley Marbell</a>, University of Cambridge, UK
  </ul>
 </div>

 <div style="width:500px;padding:10px;margin:10px;background-color:#FFFFDF;text-align:left;display:inline-block;vertical-align:top;">
  <h3>Advisory/Industrial Board (A-Z)</h3>

  <ul>
    <li><a href="https://ie.linkedin.com/in/michaelablott">Michaela Blott</a>, Xilinx
    <li><a href="https://www.linkedin.com/in/unmeshdbordoloi">Unmesh Bordoloi</a>, General Motors
    <li><a href="https://www.microsoft.com/en-us/research/people/oferd/">Ofer Dekel</a>, Microsoft
    <li><a href="http://openlab.cern/about/people/maria-girone">Maria Girone</a>, CERN openlab
    <li><a href="https://www.linkedin.com/in/waynegraves">Wayne Graves</a>, Association for Computing Machinery
    <li><a href="https://www.linkedin.com/in/vinodg">Vinod Grover</a>, NVIDIA
    <li><a href="https://www.linkedin.com/in/sumitg">Sumit Gupta</a>, IBM
    <li><a href="https://www.turing.ac.uk/research-engineering/#people">James Hetherington</a>, Alan Turing Institute
    <li><a href="http://research.nvidia.com/person/stephen-keckler">Steve Keckler</a>, NVIDIA
    <li><a href="https://www.linkedin.com/in/wei-li-a4a611">Wei Li</a>, Intel
    <li><a href="https://www.linkedin.com/in/colin-osborne-7129362/">Colin Osborne</a>, ARM
    <li><a href="https://www.microsoft.com/en-us/research/people/anputnam">Andrew Putnam</a>, Microsoft
    <li><a href="https://archive.pioneers.io/blog/people/boris-shulkin">Boris Shulkin</a>, Magna
    <li><a href="https://www.linkedin.com/in/greg-stoner-17830">Greg Stoner</a>, AMD
    <li><a href="https://www.linkedin.com/in/alexwade">Alex Wade</a>, Chan Zuckerberg Initiative
    <li><a href="https://www.linkedin.com/in/peng-wu-411b5b">Peng Wu</a>, Huawei
    <li><a href="https://research.google.com/pubs/105499.html">Cliff Young</a>, Google
  </ul>

  <i>Please <a href="mailto:anton@dividiti.com">contact us</a>
  if you are interested to join the Advisory Board!</i>

 </div>
</div>


</center>

<!---------------------------------------------------------------------------------------->
<a id="program"><h3>Workshop program</h3>

<p>
<table border="1" cellpadding="10" cellspacing="0">
 <tr style="background-color:#cfcfff;">
  <td width="120">
   <b>Time slot</b>
  </td>
  <td>
   <b>Presentation</b>
  </td>
  <td align="center">
   <b>Reusable artifacts</b>
  </td>
 </tr>

 <tr>
  <td valign="top">
   1:30p-1:40pm
  </td>
  <td valign="top">
   <b>Workshop introduction</b>
   <p>
   <p>ReQuEST tournaments bring together multidisciplinary researchers (AI, ML, systems)
    to find the most efficient solutions for realistic problems 
    requested by the advisory board in terms of speed, accuracy, energy, complexity,
    costs and other metrics across the whole application/software/hardware stack
    In a fair and reproducible way.

    All the winning solutions (code, data, workflow) on a Pareto-frontier
    are then available to the community as portable and customizable
    "plug&play" AI/ML components with a common API and meta information.

    The ultimate goal is to accelerate research and reduce costs
    by reusing the most accurate and efficient AI/ML blocks
    continuously optimized, autotuned and crowd-tuned 
    across diverse models, data sets and platforms from a cloud to edge.

  </td>
  <td align="center" valign="top">
  </td>
 </tr>

 <tr>
  <td valign="top">
   1:40p-2:30pm
  </td>
  <td valign="top">
   <b>Keynote "The Retrospect and Prospect of Low-Power Image Recognition Challenge (LPIRC)"</b>

   <p>
   <a href="http://ei-lab.org/people/faculty/yiran-chen-3">Prof. Yiran Chen</a>, Duke University, USA

   <p>
   <img src="$#ck_url_template_pull#$_resources/photo-yiran-chen-reduced-min.jpg" width="200" style="float:right;padding:10px;">

   <p>
   <b>Abstract:</b> Reducing power consumption has been one
   of the most important goals since the creation
   of electronic systems. Energy efficiency is increasingly
   important as battery-powered systems (such as smartphones,
   drones, and body cameras) are widely used. It is desirable
   using the on-board computers to recognize objects in the
   images captured by these cameras. The Low-Power Image
   Recognition Challenge (LPIRC) is an annual competition
   started in 2015, aiming to discover the best technology
   in both image recognition and energy conservation. In this
   talk, we will explains the rules of the competition and the
   rationale, summarizes the teams' scores, and describes the
   lessons learned in the past years. We will also discuss
   possible improvements of future challenges and
   collaboration opportunities with other events and
   competitions like ReQuEST.

   <p><b>Short bio:</b> Yiran Chen received B.S and M.S. from
   Tsinghua University and Ph.D. from Purdue University
   in 2005. After five years in industry, he joined University
   of Pittsburgh in 2010 as Assistant Professor and then
   promoted to Associate Professor with tenure in 2014, held
   Bicentennial Alumni Faculty Fellow. He now is a tenured
   Associate Professor of the Department of Electrical and
   Computer Engineering at Duke University and serving as the
   co-director of Duke Center for Evolutionary Intelligence
   (CEI), focusing on the research of new memory and storage
   systems, machine learning and neuromorphic computing, and
   mobile computing systems. Dr. Chen has published one book
   and more than 300 technical publications and has been
   granted 93 US patents. He is the associate editor of IEEE
   TNNLS, IEEE D&T, IEEE ESL, ACM JETC, and ACM TCPS, and
   served on the technical and organization committees of more
   than 40 international conferences. He received 6 best paper
   awards and 12 best paper nominations from international
   conferences. He is the recipient of NSF CAREER award and
   ACM SIGDA outstanding new faculty award. He is the Fellow
   of IEEE.

   <p>See <a href="https://rebootingcomputing.ieee.org/lpirc">LPIRC tournaments</a>.
  </td>
  <td align="center" valign="top">
  </td>
 </tr>

 <tr>
  <td valign="top">
   2:30pm-2:50pm
  </td>
  <td valign="top">
   <b>"Real-Time Image Recognition Using Collaborative IoT Devices"</b>
   <p>
    <u>Ramyad Hadidi</u>, Jiashen Cao, Matthew Woodward, Michael S. Ryoo, Hyesoon Kim
   <p>
   <i>Georgia Institute of Technology, USA</i>
  </td>
  <td align="center" valign="top">
   <a href="https://github.com/ctuning/ck-request-asplos18-iot-farm">Unification stage</a>

   <p>
   <i>
   Nvidia Jetson TX2, ARM, Raspberry Pi, AlexNet, VGG16, TensorFlow, Keras, Avro
   </i>

  </td>
 </tr>

 <tr>
  <td valign="top">
   2:50pm-3:10pm
  </td>
  <td valign="top">
   <b>"Highly Efficient 8-bit Low Precision Inference of Convolutional Neural Networks with IntelCaffe"</b>
   <p>
   Jiong Gong, <u>Haihao Shen</u>, Guoming Zhang, Xiaoli Liu, Shane Li, Ge Jin, Niharika Maheshwari
   <p>
   <i>Intel Corporation</i>
  </td>
  <td align="center" valign="top">
   <a href="https://github.com/ctuning/ck-request-asplos18-caffe-intel">Validated</a>

   <p>
   <i>
   Xeon Platinum 8124M, AWS, Intel C++ Compiler 17.0.5 20170817, ResNet-50, Inception-V3, SSD, 32-bit, 8-bit, Caffe
   </i>

  </td>
 </tr>

 <tr>
  <td valign="top">
   3:10pm-3:30pm
  </td>
  <td valign="top">
   <b>"VTA: Open Hardware/Software Stack for Vertical Deep Learning System Optimization"</b>
   <p>
   <u>Thierry Moreau</u>, Tianqi Chen, Luis Ceze
   <p>
   <i>
   University of Washington, USA
   </i>
  </td>
  <td align="center" valign="top">
   <a href="https://github.com/ctuning/ck-request-asplos18-mobilenets-tvm-arm">Unification stage</a>

   <p>
   <i>
   Xilinx FGPA (Pynq board), ResNet-*, MXNet, NNVM/TVM
   </i>

  </td>
 </tr>

 <tr style="background-color:#dfdfff;">
  <td valign="top">
   3:30pm-4:00pm
  </td>
  <td>
   Break
  </td>
  <td align="center">
  </td>
 </tr>

 <tr>
  <td valign="top">
   4:00pm-4:20pm
  </td>
  <td valign="top">
   <b>"Optimizing Deep Learning Workloads on ARM GPU with TVM"</b>
   <p>
   <u>Lianmin Zheng</u><sup>1</sup>, Tianqi Chen<sup>2</sup>
   <p>
   <i>
    <sup>1</sup> Shanghai Jiao Tong University, China<br>
    <sup>2</sup> University of Washington, USA
   </i>
  </td>
  <td align="center" valign="top">
   <a href="https://github.com/ctuning/ck-request-asplos18-mobilenets-tvm-arm">Unification stage</a>

   <p>
   <i>
    Firefly-RK3399, GCC, LLVM, VGG16, MobileNet, ResNet-18, OpenBLAS vs ArmCL, MXNet, NNVM/TVM
   </i>
  </td>
 </tr>

 <tr>
  <td valign="top">
   4:20pm-4:50pm
  </td>
  <td valign="top">
   <b>"Introducing open ReQuEST platform, scoreboard and long-term vision"</b>
   <p>
   <u>Grigori Fursin</u> and the ReQuEST organizers

   <p>
   <b>"Exploring performance and accuracy of the MobileNets family using the Arm Compute Library"</b>
   <p>
   Nikolay Chunosov, Flavio Vella, Anton Lokhmotov, <u>Grigori Fursin</u>
   <p>
   <i>
    dividiti, UK<br>
    cTuning foundation, France
   </i>

  </td>

  <td align="center" valign="top">
   <a href="https://github.com/dividiti/ck-request-asplos18-mobilenets-armcl-opencl">Validated</a>
   <p>
   <i>
    HiKey 960 (GPU), GCC, MobileNets exploration, ArmCL (18.01,18.02,dividiti optimizations), OpenCL
   </i>
  </td>
 </tr>

 <tr>
  <td valign="top">
  4:50pm-5:00pm
  </td>
  <td valign="top">
   <a id="panel">
   <b>Demonstrating live ReQuEST scoreboard with latest validated results</b>

   <p>
   <i>Note that the idea of ReQuEST tournaments is to continuously update this scoreboard with the help of authors and the community even after the workshop! Please, stay tuned!</i>
  </td>

  <td align="center" valign="top">
   Live <a href="http://cknowledge.org/repo/web.php?native_action=show&native_module_uoa=program.optimization&scenario=a555738be4b65860">ReQuEST scoreboard</a>
   and <a href="https://github.com/ctuning/ck-request-asplos18-results">shared ReQuEST workflow with all artifacts</a>.

   <p>
   Other shared CK artifact and workflows available <a href="https://github.com/ctuning/ck/wiki/Shared-repos#user-content-shared-workflows">here</a>.
  </td>
 </tr>

 <tr>
  <td valign="top">
   5:00pm
  </td>
  <td>
    Open panel and discussion: 
    <b>
     "Tackling complexity, reproducibility and tech transfer challenges in a rapidly evolving AI/ML/systems research"
    </b>

    <p>
    Moderators: <a href="http://fursin.net/research.html">Grigori Fursin</a> 
    and <a href="https://homes.cs.washington.edu/~moreau">Thierry Moreau</a>.

    <p>
    We plan to center discussion around the following questions:
    <ul>
     <li>
      How do we facilitate tech transfer between academia and
      industry in a quickly evolving research landscape?
     <li>
      How do we incentivize companies and academic researchers 
      to release more artifacts and open source projects as portable,
      customizable and reusable components which can be
      collaboratively optimized by the community across
      diverse models, data sets and platforms from the cloud
      to edge?
     <li>
      How do we ensure reproducible evaluation and fair comparison 
      of diverse AI/ML frameworks, libraries, techniques and tools?
     <li>
      What other workloads (AI, ML, quantum) and exciting
      research challenges should ReQuEST attempt to solve
      in its future iterations with the help of the
      multi-disciplinary community: reducing training time and
      costs, comparing specialized hardware (TPU/FPGA/DSP),
      distributing learning across edge devices, ...
    </ul>

    <p>
    <h3>Participants:</h3>

    <p>
    <table border="0" cellpadding="12" cellspacing="0">

     <tr>
      <td valign="top">
       <b>Hillery Hunter, IBM</b>

       <p>
       <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-hhunter">Hillery Hunter</a> 
       is an IBM Fellow and Director of the Accelerated Cognitive
       Infrastructure group at IBM's T.J. Watson Research Center
       in Yorktown Heights, NY. She is interested
       in cross-disciplinary technology topics, spanning silicon
       to system architecture to achieve new solutions to traditional
       problems. Her team pursues hardware-software co-optimization
       to take the wait time out of machine and deep learning
       problems.  Her prior work was in the areas of DRAM main memory
       systems and embedded DRAM, and she gained development
       experience serving as IBM's server and mainframe
       DDR3-generation end-to-end memory power lead. In 2010, she was
       selected by the National Academy of Engineering for its
       Frontiers in Engineering Symposium, a recognition as one of
       the top young engineers in America. Dr. Hunter received the
       Ph.D. degree in Electrical Engineering from the University
       of Illinois, Urbana-Champaign and is a member of the IBM
       Academy of Technology.  Hillery was appointed as an IBM Fellow
       in 2017.
      </td>
      <td valign="top">
       <img src="$#ck_url_template_pull#$_resources/photo-hilary-hunter.jpg" width="210" style="float:right;padding:10px;">
      </td>
     </tr>

     <tr>
      <td valign="top">
       <b>Yiran Chen, Duke University</b>

       <p>
       <a href="http://ei-lab.org/people/faculty/yiran-chen-3/">Yiran Chen</a> 
       received B.S and M.S. from
       Tsinghua University and Ph.D. from Purdue University
       in 2005. After five years in industry, he joined University
       of Pittsburgh in 2010 as Assistant Professor and then
       promoted to Associate Professor with tenure in 2014, held
       Bicentennial Alumni Faculty Fellow. He now is a tenured
       Associate Professor of the Department of Electrical and
       Computer Engineering at Duke University and serving as the
       co-director of Duke Center for Evolutionary Intelligence
       (CEI), focusing on the research of new memory and storage
       systems, machine learning and neuromorphic computing, and
       mobile computing systems. Dr. Chen has published one book
       and more than 300 technical publications and has been
       granted 93 US patents. He is the associate editor of IEEE
       TNNLS, IEEE D&T, IEEE ESL, ACM JETC, and ACM TCPS, and
       served on the technical and organization committees of more
       than 40 international conferences. He received 6 best paper
       awards and 12 best paper nominations from international
       conferences. He is the recipient of NSF CAREER award and
       ACM SIGDA outstanding new faculty award. He is the Fellow
       of IEEE.

      </td>
      <td valign="top">
       <img src="$#ck_url_template_pull#$_resources/photo-yiran-chen-reduced-min.jpg" width="160" style="float:right;padding:10px;">
      </td>
     </tr>

     <tr>
      <td valign="top">
       <b>Charles Qi, Cadence</b>

       <p>
       <a href="https://www.linkedin.com/in/charlesqi">Charles Qi</a> 
       is a system solutions architect in Cadence's
       IPG System and Software team, responsible for providing
       vision system solutions based on the Cadence(R) Tensilica
       Vision DSP technology and a broad range of interface
       IP portfolio. At system level, his primary focus
       is image sensing, computer vision and deep learning
       hardware and software for high-performance automotive
       vision ADAS SoC. Currently he is also an active internal
       architecture team member for high performance neural
       network acceleration hardware IPs.

       Prior to joining Cadence, Charles held various technical
       positions in Intel, Broadcom and several high-tech
       startups.

      </td>
      <td valign="top">
       <img src="$#ck_url_template_pull#$_resources/photo-charles-qi-reduced-min.jpg" width="160" style="float:right;padding:10px;">
      </td>
     </tr>

     <tr>
      <td valign="top">
       <b>Tianqi Chen, University of Washington</b>

       <p>
       <a href="https://homes.cs.washington.edu/~tqchen">Tianqi Chen</a> 
       is a PhD student in University of Washington, and
       recipient of a Google PhD Fellowship in Machine
       Learning. Tianqi is creator of popular machine learning
       systems, such as XGBoost, ApacheMXNet and the TVM
       stack. XGBoost has been adopted by many industries such
       as Uber, Airbnb, Tencent, while ApacheMXNet has seen
       wide adoption by Intel, NVIDIA, AWS, and Wolfram among
       others. He will share his experience about creating and
       managing production quality AI frameworks originating
       from academic research.

      </td>
      <td valign="top">
       <img src="$#ck_url_template_pull#$_resources/photo-tianqi-chen-reduced-min.jpg" width="160" style="float:right;padding:10px;">
      </td>
     </tr>

    </table>

  </td>
  <td align="center">
  </td>
 </tr>

</table>


<!---------------------------------------------------------------------------------------->
<a id="important_dates"><h3>Important dates</h3>
<ul>
<!-- <li>Informal intent to submit: <b>February 7, 2018 AoE</b><br> 
     &nbsp;&nbsp;<i>Please send us an <a href="mailto:moreau@cs.washington.edu;Grigori.Fursin@cTuning.org">email</a>
     briefly describing your submission including hardware/software dependencies
     and optimization metrics. We will start helping you convert your artifacts 
     to the <a href="http://cKnowledge.org">Collective Knowledge</a> format.</i> -->
 <li>Artifact submissions due: <b><strike>February 12, 2018 AoE</strike></b><br>
 <li>Artifact evaluation: <b><strike>February 13-February 21, 2018</strike></b>
 <li>Author notification: <b><strike>February  22, 2018</strike></b>
 <li>ASPLOS early registration deadline: <b><strike>February 23, 2018</strike></b> 
     (See <a href="https://www.asplos2018.org/registration/#reg">ASPLOS resigration</a> 
     and <a href="https://www.asplos2018.org/registration/#visa">visa support</a>)
 <li>Revised artifacts and papers due: <b>March 19, 2018</b>
 <li>Workshop with presentations and discussions of winning workflows: <b>March 24, 2018</b>
</ul>

<!---------------------------------------------------------------------------------------->
<a id="call"><h3>Call for submissions</h3>

<p>
The 1st ReQuEST tournament is co-located with <a href="https://www.asplos2018.org">ACM ASPLOS'18</a>
and will focus on optimizing the whole model/software/hardware stack for image classification
based on the <a href="http://www.image-net.org/challenges/LSVRC"><b>ImageNet Large Scale Visual Recognition Challenge (ILSVRC)</b></a>.

Unlike the classical ILSVRC where submissions are ranked according to their
classification accuracy, however, ReQuEST submissions will be evaluated 
according to multiple metrics and trade-offs selected by the authors 
(e.g. accuracy, speed, throughput, energy consumption, hardware cost, usage cost, etc.)
in a unified, reproducible and objective way
using the <a href="https://github.com/ctuning/ck">Collective Knowledge</a> framework (CK).

Restricting the competition to a single application domain will allow us 
to test our open-source ReQuEST tournament infrastructure, 
validate it across multiple platforms and environments, 
and prepare a dedicated live scoreboard with results
similar to this <a href="http://cKnowledge.org/repo">public CK scoreboard</a>.

<p>
We encourage participants to target accessible, off-the-shelf hardware to allow
our evaluation committee to conveniently reproduce their results. Example systems include:
<ul>
 <li> 
  Server-class: AWS/Azure cloud instance, any x86-based desktop system.
 </li>
 <li>
  Mobile-class: Any ARM-based (e.g. NVIDIA Jetson TX2, Raspberry Pi 3, Xilinx PYNQ board), or Intel-Atom-based SoC development board, Android-based smartphone or tablets.
 </li>
 <li>
  IoT-class: Low-power ARM micro-controllers (e.g. Freescale FRDM KL03 Development Board).
 </li>
</ul>

If a submission relies on an exotic hardware platform, the participants can
either provide restricted access to their evaluation platform to the artifact
evaluation committee, or notify the organizers in advance (please try to give
us at least 3 weeks notice) about their choice so that a similar platform can
be acquired in time (assuming the cost is not prohibitive).

<p>
Example optimizations include:
<ul>
 <li>Design space exploration of model topologies, operators, activation functions, configurations.
 <li>Hyper-parameter search and meta-learning techniques that help optimize accuracy and inference time.
 <li>Comparison of different deep learning systems (for example TensorFlow vs. Caffe2 vs. CNTK vs. MXNet).
 <li>Model optimizations that trade accuracy for speed or efficiency (e.g. reduced precision and model compression).
 <li>Operator-level quantization, binarization or ternarization techniques to improve overall inference time (e.g. binary networks, XNOR nets).
 <li>Library optimizations targeting deep learning operators on mobile systems (e.g. depthwise convolution).
 <li>FPGA acceleration that takes advantage of narrow integer bitwidth.
 <li>Software optimizations targeting GPU-less mobile/IoT systems.
</ul>

 <div style="color:#9f0000;">
 <i>We strongly encourage artifact submissions for already published optimization 
 techniques since one of the ReQuEST goals is to prepare 
 a reference (baseline) set of implementations of various algorithms 
 shared as portable, customizable and reusable CK components 
 with a common API. 
 
 In fact, the ReQuEST submissions will be directly fed into <a href="https://www.acm.org/publications/dl-pilot-integrations">pilot CK integrations with the ACM Digital Library</a>. </i>
 </div>

<!---------------------------------------------------------------------------------------->
<a id="submission"><h3>Submission</h3>

We follow <a href="http://ctuning.org/ae/submission.html">standard
procedures</a> for submitting and evaluating experimental workflows, as
established at leading systems conferences including CGO, PPoPP, PACT and
SuperComputing ("artifact evaluation"):

<p>

<div style="padding:5px;">
 <!------------------------------------------------------------------------->
 <b>Step 1: Share your experimental artifacts and workflows</b>

 <div style="padding:5px;">
   You should make all artifacts and experimental workflows publicly available
   via GitHub, GitLab, Bitbucket or similar, or pack them in a zip/tar archive 
   or Docker/VM image.

   You should also provide instructions and scripts to build and run your
   workflows on a target platform, measure the characteristics and compare the
   results against a reference implementation.
   
   <p> If you are already familiar with the open-source <a
   href="http://github.com/ctuning/ck">Collective Knowledge</a> framework (CK),
   you are encouraged to convert your experimental workflows to to <a
   href="https://github.com/ctuning/ck/wiki/Portable-workflows">portable CK
   workflows</a>.  Such workflows can automatically set up the environment,
   detect required software dependencies, install missing packages and run
   experiments, thus automating artifact evaluation.  (See some examples <a
   href="https://github.com/ctuning/ck/wiki/Shared-repos#user-content-shared-workflows">here</a>.)

   <p> If you are not familiar with CK, worry not! We will gladly help you
   convert your submission to CK during the <a href="#evaluation">evalution
   stage</a>.
 </div>

 <!------------------------------------------------------------------------->
 <b>Step 2: Submit an extended abstract with Artifact Appendix</b>

 <div style="padding:5px;">
   You should prepare an extended abstract (max 4 pages)
   using this <a href="http://cKnowledge.org/request/request-template.tex">ReQuEST LaTex template</a> 
   in the <a href="http://www.sigplan.org/sites/default/files/sigplanconf.cls">SIGPLAN conference style</a>.

   Include your name, affiliation, and a brief description of your work (which
   can be novel or already presented elsewhere). Please also fill in the
   Artifact Appendix in the above template, including how to obtain your
   artifacts and workflows. Provide a detailed specification of your
   experimental workflow, a list of optimization metrics (speed, accuracy,
   energy, costs, etc.) and the expected results (which the reviewers will need
   to independently validate).

   Please submit your extended abstract as a PDF via the <a
   href="https://asplos18request.hotcrp.com">ReQuEST HotCRP website</a>.
   Please contact the <a
   href="mailto:moreau@cs.washington.edu;Grigori.Fursin@cTuning.org">organizers</a>
   if your encounter any problems.
 </div>

</div>

<!---------------------------------------------------------------------------------------->
<a id="evaluation"><h3>Evaluation</h3>

 ReQuEST is backed by the <a href="https://www.acm.org/publications/task-force-on-data-software-and-reproducibility">ACM Task Force on Data, Software, and Reproducibility in Publication</a>
 and uses the standard <a href="http://cTuning.org/ae/reviewing.html">artifact evaluation methodology</a>.
 Artifact evaluation is single blind (see <a href="http://cTuning.org/ae">PPoPP, CGO, PACT, RTSS and SuperComputing</a>).
 Reviews will be performed by the <a href="#organizers">organizers</a> and volunteers ("reviewers"), and can be made public upon the authors' request (see <a href="http://adapt-workshop.org/submission2016.html">ADAPT</a>).
 Quality and efficiency metrics will be collected for each submission, and displayed on a live ReQuEST scoreboard similar 
 to this <a href="http://cKnowledge.org/repo">open CK repository</a>.

<div style="padding:5px;">
 <p>
 <!------------------------------------------------------------------------->
 <b>Step 1: Collaborate on converting your workflows to CK</b>

 <div style="padding:5px;">
  If your submission is not in the CK format, we will help you convert it to the CK format
  while reusing various artifacts already shared by the community
 (see <a href="https://github.com/ctuning/ck/wiki/Shared-repos#user-content-shared-workflows">CK AI repositories</a>,
  <a href="https://github.com/ctuning/ck/wiki/Shared-modules">CK modules (wrappers)</a>,
  <a href="https://github.com/ctuning/ck/wiki/Shared-soft-descriptions">CK software detection plugins</a>,
  <a href="https://github.com/ctuning/ck/wiki/Shared-packages">portable CK packages</a>).

  You may choose how to communicate with us during this step: either privately via HotCRP,
  semi-privately via a <a href="https://request-workshop.slack.com">dedicated Slack channel with all authors and reviewers</a>,
  or, <a href="http://adapt-workshop.org/motivation2016.html">preferably</a>,
  publicly via the <a href="https://groups.google.com/forum/#!forum/collective-knowledge">CK mailing list</a>
  (thus making the community immediately aware of your artifact).
 </div>

 <!------------------------------------------------------------------------->
 <p>
 <b>Step 2: Collaborate on validating your results</b>

 <div style="padding:5px;">
  We will form a ReQuEST artifact evaluation committee (AEC) from the
  organizers and volunteers (&quot;reviewers&quot;).  The AEC task is to
  objectively evaluate submissions on appropriate hardware platforms,
  reproduce results and aggregate them on a multi-objective public scoreboard. 

  AE will be a friendly and interactive process between the authors and the
  reviewers, with the goal of making the artifacts as useful as possible for
  the community. For example, the reviewers may encounter some unexpected
  problems, and ask the authors for help to fix them.

  <p>
  Again, the authors can communicate with the reviewers privately via HotCRP,
  semi-privately via <a href="https://request-workshop.slack.com">Slack</a>,
  or publicly by opening tickets in shared repositories (see examples <a
  href="https://github.com/thu-pacman/self-checkpoint/issues/1">1</a> and <a
  href="https://gitlab.com/michel-steuwer/cgo_2017_artifact/issues/1">2</a>)
  and/or via the <a href="https://groups.google.com/forum/#!forum/collective-knowledge">CK mailing list</a>.

  If any of the organizers submit their workflows (mainly to provide reference
  implementations), their submissions will go through public evaluation.

  <p>
 </div>

 <!------------------------------------------------------------------------->
 <b>Step 3: Collaborate on visualizing your results on a public scoreboard</b>

 <div style="padding:5px;">

  <p>
  
  Due to the multi-faceted nature of the competition, submissions will not
  be ranked according to a single metric (as this often results in
  over-engineered solutions), but instead the AEC will assess their Pareto
  optimality on two or more metrics exposed by the authors.  As such, there
  will not be a single winner, but rather better and worse designs based on
  their relative Pareto optimality (up to 3 design points allowed per each
  submission).

  We will collaborate with the authors to correctly visualize the results and
  SW/HW/model configurations on a  <a href="http://cKnowledge.org/repo">public
  scoreboard</a> while grouping them according to certain categories of their
  choice (e.g. embedded vs. server). A unique submission may define a
  category in its own right.

  To win, the results of an entry will normally lie close to the Pareto-optimal
  frontier in its category.  However, a winning entry can be also praised for
  its originality, reproducibility, adaptability, scalability, portability,
  ease of use, etc.
 </div>
</div>

<!---------------------------------------------------------------------------------------->
<a id="Presentation"><h3>Presentation</h3>

<div style="padding:5px;">
 <!------------------------------------------------------------------------->
 <b>Step 1: Present at the ReQuEST workshop at ASPLOS'18</b>

 <p>
 <div style="padding:5px;">
  
  We will announce the winning SW/HW/model configurations at the end of
  February, and invite the authors to present their work at the 1st ReQuEST
  workshop co-located with <a href="https://www.asplos2018.org">ASPLOS 2018</a>
  (ACM conference on Architectural Support for Programming Languages and
  Operating Systems, which is the premier forum for multidisciplinary systems
  research spanning computer architecture and hardware, programming languages
  and compilers, operating systems and networking).

  This will give the authors an opportunity to share their research and
  implementation insights with the research community as well as discuss future
  R&amp;D directions.

  <p>
  A common academic and industrial panel will be held at the end of the
  workshop to discuss how to improve the common SW/HW co-design methodology
  and infrastructure for deep learning and other real-world workloads.

 </div>

 <!------------------------------------------------------------------------->
 <b>Step 2: Publish in the ACM Digital Library</b>

 <p>
 <div style="padding:5px;">

  The authors of the winning submissions will publish their extended abstracts with an Artifact Appendix
  and related artifacts in the <a href="http://dl.acm.org">ACM Digital Library</a> 
  (even if their techniques have already been published, since the workshop focuses on validated and reusable artifacts!) 

  <i>Furthermore, we have partnered with <a href="http://acm.org">ACM</a> to award 
  <a href="https://www.acm.org/publications/policies/artifact-review-badging">&quot;available / reusable / replicated&quot; badges</a>
  to all the winning artifacts. 

  This will make them discoverable via the ACM Digital Library
  (check this out by selecting &quot;Artifact Badge&quot; for a field and then select any badge you wish 
  in the <a href="https://dl.acm.org/advsearch.cfm?coll=DL&dl=ACM">ACM DL advanced search</a>)!</i>

  <p>
  <center>
   <img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_available_dl.jpg" width="50">
   <img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_evaluated_reusable_dl.jpg" width="50">
   <img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/results_replicated_dl.jpg" width="50">
  </center>
 </div>

</div>

<center>
<b>Feel free to <a href="mailto:moreau@cs.washington.edu;Grigori.Fursin@cTuning.org;anton@dividiti.com">contact us</a> if you have questions or suggestions!</b>
</center>

<!---------------------------------------------------------------------------------------->
<a id="industrial_board"><h3>Advisory/industrial board</h3>

 <p> After the workshop, we will prepare a public report for the
 ReQuEST Advisory/Industrial Board.  The board members will provide their
 feedback on the results, collaborate on a common methodology for reproducible
 evaluation and optimization, suggest realistic workloads, help provide access
 to rare hardware platforms to the Artifact Evaluation Committee for future
 tournaments, and provide prizes for distinguished entries.

<!---------------------------------------------------------------------------------------->
<!-- 
<a id="overview"><h3>Open tournament framework</h3>
<center><a href="https://www.slideshare.net/GrigoriFursin/adapting-to-a-cambrian-aiswhw-explosion-with-open-codesign-competitions-and-collective-knowledge"><img src="$#ck_url_template_pull#$_resources/b4b07ad3a7839327-cropped.png" width="600"></a></center>
 -->
<br>
<br>

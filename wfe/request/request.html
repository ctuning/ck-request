<!-- copied from ck-request repo! -->

<!---------------------------------------------------------------------------------------->
<center>
<h2>ReQuEST: Reproducible Quality-Efficient Systems Tournaments</h2>
<i>
aka Multi-Objective HW/SW Co-Design Competitions for Emerging Workloads
</i>
</center>

<center>
 <a href="https://www.cornell.edu"><img src="$#ck_url_template_pull#$_resources/logo-cornell-university3.png" style="padding:10px;" width="70" /></a>
 <a href="https://www.washington.edu"><img src="$#ck_url_template_pull#$_resources/logo-university-of-washington2.png" style="padding:10px;" width="200"/></a>
 <a href="https://www.cam.ac.uk"><img src="$#ck_url_template_pull#$_resources/logo-university-of-cambridge2.png" style="padding:10px;" width="70" /></a>
 <a href="https://www.epfl.ch"><img src="$#ck_url_template_pull#$_resources/logo-epfl2.png" style="padding:10px;" width="140"/></a>
 <a href="https://www.utoronto.ca/"><img src="$#ck_url_template_pull#$_resources/logo-university-of-toronto2.png" style="padding:10px;" width="160"/></a>
 <a href="http://dividiti.com"><img src="$#ck_url_template_pull#$_resources/logo_dvdt_500.png" style="padding:10px;"  width="38"/></a>
 <a href="http://cTuning.org"><img src="$#ck_url_template_pull#$_resources/CTuning_foundation_logo3.png" style="padding:10px;"  width="110"/></a>
 <a href="http://sigarch.org"><img src="$#ck_url_template_pull#$_resources/logo-sigarch.png" style="padding:10px;" width="180" /></a>
 <a href="http://acm.org"><img src="$#ck_url_template_pull#$_resources/logo_acm_resized.jpg" style="padding:10px;" width="75" /></a>
</center>


<br>
<div id="ck_menu2">
 <div style="background-color:#e5e5FF;padding:5px;margin:5px">
  <center>
   <a href="#ongoing">Ongoing tournaments</a>
   &nbsp;&nbsp;&nbsp;
   <a href="#news">ReQuEST news</a>
   &nbsp;&nbsp;&nbsp;
   <a href="#organizers">Organizers</a>
   &nbsp;&nbsp;&nbsp;
   <a href="#goals">Goals</a>
   &nbsp;&nbsp;&nbsp;
   <a href="#industrial_board">Industrial board</a>
   &nbsp;&nbsp;&nbsp;
   <a href="#workshops">Workshops</a>
  </center>
 </div>
</div>

<!---------------------------------------------------------------------------------------->
<a id="ongoing"><h3>Ongoing tournaments/workshops</h3>

<ul>
 <li><b>2018:</b> <a href="$#ck_root_page_url#$request-cfp-asplos2018$#ck_page_suffix#$">1st ReQuEST tournament at ASPLOS'18 to co-design Pareto-efficient deep learning stack (inference)</a>.
</ul>

<!---------------------------------------------------------------------------------------->
<a id="news"><h3>News</h3>

<ul>
 <li><b>2018.Jan:</b> We partnered with <a href="http://acm.org">ACM</a> to award 
   <a href="https://www.acm.org/publications/policies/artifact-review-badging">"available, reusable, replicated" badges</a> 
   to all winning artifacts and make them discoverable via <a href="https://dl.acm.org/advsearch.cfm?coll=DL&dl=ACM">ACM Digital Library search</a>
   (select "Artifact Badge" for field and then select badges to search).
 <li><b>2018.Jan:</b> Brief ReQuEST introduction is now available in <a href="http://arxiv.org/abs/1801.06378">ArXiv</a>.
 <li><b>2017.Dec:</b> Open call for Pareto efficient, portable and reusable deep learning algorithms - 
  <a href="$#ck_root_page_url#$request-cfp-asplos2018$#ck_page_suffix#$">1st ReQuEST tournament at ASPLOS'18</a> <i>(Intent to submit: <b>February 5, 2018</b>)</i>
 <li><b>2017.Dec:</b> Interesting discussion about ReQuEST on Reddit (<a href="https://www.reddit.com/r/MachineLearning/comments/7hgrnw/n_1st_open_tournament_on_pareto_efficient_deep/">link</a>)
</ul>

<!---------------------------------------------------------------------------------------->
<a id="organizers"><h3>Organizers (A-Z)</h3>

<ul>
 <li><a href="https://www.cs.washington.edu/people/faculty/luisceze">Luis Ceze</a>, University of Washington, USA
 <li><a href="http://www.eecg.toronto.edu/~enright">Natalie Enright Jerger</a>, University of Toronto, Canada
 <li><a href="https://parsa.epfl.ch/~falsafi">Babak Falsafi</a>, EPFL, Switzerland
 <li><a href="http://fursin.net/research.html">Grigori Fursin</a>, cTuning foundation, France <i>(Artifact Evaluation/Framework chair)</i>
 <li><a href="https://uk.linkedin.com/in/lokhmotov">Anton Lokhmotov</a>, dividiti, UK <i>(Industrial chair)</i>
 <li><a href="https://homes.cs.washington.edu/~moreau">Thierry Moreau</a>, University of Washington, USA <i>(Publicity chair)</i>
 <li><a href="http://www.cs.cornell.edu/~asampson">Adrian Sampson</a>, Cornell University, USA
 <li><a href="https://www.energy.cam.ac.uk/directory/ps751@cam.ac.uk">Phillip Stanley Marbell</a>, University of Cambridge, UK
</ul>

<!---------------------------------------------------------------------------------------->
<a id="goals"><h3>Long-term vision</h3>

<div style="margin-left:30px;">

  <!---------------------------------------------------------------------------------------->
  <h4>Summary</h4>

  <div style="margin-left:20px;">
   ReQuEST is aimed at providing a scalable tournament framework,
   a common experimental methodology and an open repository 
   for continuous evaluation and optimization 
   of the quality vs. efficiency 
   Pareto optimality of a wide range of real-world applications,
   libraries and models across the whole hardware/software stack
   on complete platforms.
  </div>

  <!---------------------------------------------------------------------------------------->
  <h4>Tournament framework goals</h4>

  <div style="margin-left:20px;">
   ReQuEST promotes reproducibility of experimental results 
   and reusability/customization of systems research artifacts 
   by standardizing evaluation methodologies 
   and facilitating the deployment of efficient solutions 
   on heterogeneous platforms. 
   That is why we build our competition on top of an open-source and portable 
   workflow framework (<a href="https://github.com/ctuning/ck">Collective Knowledge or CK</a>)
   and a <a href="http://cTuning.org/ae">standard artifact evaluation methodology</a>
   from premier ACM systems conferences (CGO, PPoPP, PACT, SuperComputing)to provide unified evaluation and
   a real-time leader-board of submissions. 
  <!-- Yearly competition workshops are held at top-tier conferences 
   to discuss insights and results from the tournament. -->

     <p>
     <b>We partnered with <a href="http://acm.org">ACM</a> to award 
     <a href="https://www.acm.org/publications/policies/artifact-review-badging">"available, reusable, replicated" badges</a>
     to all winning artifacts and make them discoverable via ACM Digital Library
     (check it out by selecting "Artifact Badge" for field and then select any badge you wish 
     in the <a href="https://dl.acm.org/advsearch.cfm?coll=DL&dl=ACM">ACM DL advanced search</a>)!</b>

     <p>
     <center>
      <img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_available_dl.jpg">
      <img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_evaluated_reusable_dl.jpg">
      <img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/results_replicated_dl.jpg">
     </center>

  </div>

  <!---------------------------------------------------------------------------------------->
  <h4>Metrics and Pareto-optimality goals</h4>

  <div style="margin-left:20px;">
   ReQuEST promotes quality-awareness to the architecture and systems community, 
   and resource-awareness to the applications community and end-users. 

   The submissions and their evaluation metrics will be maintained
   in a public repository that includes a live leader board.
   Specific attention will be brought to submissions
   close to a Pareto frontier in a multi-dimensional space
   of accuracy, execution time, power/energy consumption,
   hardware/code/model footprint, monetary costs etc.

   <!-- Eventually we may want to converge on a few meaningful metrics 
   to assess quality on a per-application basis, 
   and efficiency on a per-platform basis. -->
  </div>

  <!---------------------------------------------------------------------------------------->
  <h4>Application goals</h4>

  <div style="margin-left:20px;">
   In the long term, ReQuest will cover a comprehensive suite of workloads, datasets and models
   covering applications domains that are most relevant to researchers in academia and industry
   (AI, vision, robotics, quantum computing, scientific computing, etc).
   This suite will evolve according to feedback and contributions from the community 
   thus substituting ad-hoc, artificial, quickly outdated or non-representative benchmarks.
   Furthermore, all artifacts from this suite can be automatically plugged in to the ReQuEST 
   competition workflows to simplify, automate and accelerate systems research.
  </div>

  <!---------------------------------------------------------------------------------------->
  <h4>Complete platforms goals</h4>

  <div style="margin-left:20px;">
   ReQuEST aims at covering a comprehensive set of hardware systems from data-centers down 
   to sensory nodes, incorporating various forms of processors including GPUs, DSPs, FPGAs, 
   neuromorphic and even analogue accelerators in the long term. 
  </div>

  <!---------------------------------------------------------------------------------------->
  <h4>Open systems research goal</h4>

  <div style="margin-left:20px;">
   ReQuest attempts to put systems researchers, application engineers and end-users on the same ground
   by providing a common and portable evaluation framework while sharing all artifacts and optimization results
   in an open and reproducible way.

   We expect that our open repository with customizable, reusable and optimized artifacts will be useful for

   <ul>
    <li>
     scientists to accelerate their research by picking up the most efficient, resource-aware 
     and input-adaptable solutions for their algorithms;
    </li>
    <li>
     SW/HW researchers to reuse, improve and build upon each others' work
     (main pillars of open science) thus accelerating machine learning and systems research;
    </li>
    <li>
     system designers and integrators to accelerate development of the next generation of efficient hardware and software
     for emerging workloads such as deep learning using publicly validated optimization results.
    </li>
  </div>

</div>


<center>See <a href="http://cknowledge.org/repo/web.php?wcid=1e348bd6ab43ce8a:a3ac71cab714a4da">ReQuEST introduction report</a> 
and <a href="https://www.slideshare.net/GrigoriFursin/adapting-to-a-cambrian-aiswhw-explosion-with-open-codesign-competitions-and-collective-knowledge">CK presentation</a> for more details.
</center>

<!---------------------------------------------------------------------------------------->
<a id="framework"><h3>Open Tournament Framework</h3>

<center><a href="https://www.slideshare.net/GrigoriFursin/adapting-to-a-cambrian-aiswhw-explosion-with-open-codesign-competitions-and-collective-knowledge"><img src="$#ck_url_template_pull#$_resources/b4b07ad3a7839327-cropped.png" width="600"></a></center>

<div style="margin-left:30px;">
  <!---------------------------------------------------------------------------------------->
  <a id="submission"><h4>Submission</h4>

  <div style="margin-left:20px;">
   Authors need to submit a short document (4 pages max) with their names and affiliations,
   brief description of the optimization technique, a detailed specification of the
   experimental workflow including all related artifacts and evaluation
   methodology, and improved metrics to compete with other submissions.
   The document should follow the <a href="http://cKnowledge.org/request/request-template.tex">ReQuEST LaTex template</a> 
   with <a href="http://www.sigplan.org/sites/default/files/sigplanconf.cls">SIGPLAN conference style</a>
   and an <a href="http://cTuning.org/ae/submission.html">ACM Artifact Appendix</a>.

   <p>
   <div style="color:#9f0000;">
   <i>Note that novelty of the implemented techniques is not a requirement! 
   We actually strongly encourage artifact submissions of already published techniques for which artifacts don't exist yet.
   We will independently reproduce them to prepare an open set of reference implementations
   of popular algorithms/frameworks/optimizations in a form of portable and customizable workflows
   which can be easily reused and build upon!</i>
   </div>

   <p>
   We want to put every submission on the same page. For that reason we use the open-source 
   <a href=" http://cKnowledge.org/repo ">Collective Knowledge workflow framework (CK)</a>.
   CK helps <a href="http://cknowledge.org/partners.html">the community</a> share artifacts 
   (models, data sets, libraries, tools) as reusable and customizable components with a common JSON API and meta description.
   CK also helps implement portable workflows which can <a href="https://github.com/ctuning/ck/wiki/Portable-workflows">adapt to a user environment</a> 
   on Linux, Windows, MacOS and Android.
   <a href="http://acm.org">ACM</a> currently <a href="https://dl.acm.org/reproducibility.cfm">evaluates CK</a> 
   to enabling sharing of reusable and portable artifacts in an ACM Digital Library.

   <p>
   Non-profit cTuning foundation will help authors convert their artifacts and experimental scripts to the CK format
   during <i>one-week workflow unification stage</i> while reusing AI artifacts 
   already shared by the community in the CK format
   (see <a href="https://github.com/ctuning/ck/wiki/Shared-repos#ck-powered-projects-with-whole-experimental-setups-artifacts-and-workflows-shared-in-ck-format">CK AI repositories</a>,
    <a href="https://github.com/ctuning/ck/wiki/Shared-modules">CK modules (wrappers)</a>,
    <a href="https://github.com/ctuning/ck/wiki/Shared-soft-descriptions">CK software detection plugins</a>,
    <a href="https://github.com/ctuning/ck/wiki/Shared-packages">portable CK packages</a>).

   Authors can also try to convert their workflows to the CK format themselves
   using the distinguished artifact from ACM CGO'17 as an example (
   see <a href="https://github.com/SamAinsworth/reproduce-cgo2017-paper">Artifact repository at GitHub</a>, 
   <a href="http://ctuning.org/ae/resources/paper-with-distinguished-ck-artifact-and-ae-appendix-cgo2017.pdf">Artifact Appendix</a>,
   <a href="https://github.com/ctuning/ck/wiki/Artifact-sharing">CK notes</a>,
   <a href="https://github.com/ctuning/ck/wiki/Portable-workflows">CK portable workflows</a>) 
   though the learning curve is still quite steep - we plan to prepare CK tutorials
   based on the feeback from the participants.

  </div>

  <!---------------------------------------------------------------------------------------->
  <h4>Target Application</h4>

  <div style="margin-left:20px;">
   For the first iteration of ReQuEST at ASPLOS'18, we focus on Deep Learning.
   Our first step is to provide coverage for the
   <a href="http://www.image-net.org/">ImageNet</a> 
   image classification challenge.
   Restricting the competition to a single application domain will allow us to prepare an open-source
   tournament infrastructure and validate it across multiple hardware platforms, deep learning frameworks, libraries, models and inputs.
   For future incarnations of ReQuEST, we will provide broader application coverage, based on the interests of the research community and the direction
   set by our industrial board.

   <p>
   Though our main focus is on end-to-end applications, we plan to allow future submissions for (micro)kernels 
   such as matrix multiply, convolutions and transfer functions to facilitate
   participation from the compilers and computer architecture community.
   <!-- However, we will provide a separate scoreboard for such submissions. -->

  </div>

  <!---------------------------------------------------------------------------------------->
  <h4>Target Platforms</h4>

  <div style="margin-left:20px;">
   We encourage participants to target accessible, off-the-shelf
   hardware to allow
   our artifact evaluation committee to conveniently reproduce their results. Example systems include:
   <ul>
    <li> 
     Server-class: AWS/Azure cloud instance, any x86-based desktop system.
    </li>
    <li>
     Mobile-class: Any ARM-based (e.g. NVIDIA Jetson TX2, Raspberry Pi 3, Xilinx PYNQ board), or Intel-Atom-based SoC development board, Android-based smartphone or tablets.
    </li>
    <li>
     IoT-class: Low-power ARM micro-controllers (e.g. Freescale FRDM KL03 Development Board).
    </li>
   </ul>

   If a submission relies on an exotic hardware platform,
   the participants can
   either provide restricted access to their evaluation platform
   to the artifact evaluation committee, or at least notify 
   in advance (at least 3 weeks notice) the organizers of their choice so that a similar platform 
   can be acquired in time (assuming costs are not prohibitive).

   <!-- <p>
   We plan to certify 1-2 power analyzers supported 
   by our evaluation framework. The organizing
   committee may use a high-precision power analyzer 
   (e.g. Yokogawa WT310 used for LPIRC costing $3,000-4,000)
   to calibrate a low-cost power analyzer (e.g. Hardkernel
   SmartPower2 costing $37), and use the calibration results
   when determining the winners. -->

   <p>
   In the longer term, we also plan to provide support for simulator-based
   evaluations for architecture/micro-architecture research.
   <!-- Simulator-based research will be presented in a separate leaderboard
   with meta-performance models
   to extrapolate public simulation results to real systems and help 
   refine models used in simulators.
   When validated, we can "promote" simulation results to the main scoreboard. -->
   
  </div>

  <!---------------------------------------------------------------------------------------->
  <h4>Evaluation and Leader Board</h4>

  <div style="margin-left:20px;">
   ReQuest is backed by the <a href="https://www.acm.org/publications/task-force-on-data-software-and-reproducibility">ACM Task Force on Data, Software, and Reproducibility in Publication</a>
   and will use the standard <a href="http://cTuning.org/ae/reviewing.html">ACM artifact evaluation methodology</a>.
   Artifact evaluation will be single blind (see <a href="http://cTuning.org/ae">PPoPP, CGO, PACT, RTSS and SuperComputing</a>),
   and the reviews can be made public (see <a href="http://adapt-workshop.org/submission2016.html">ADAPT</a>) upon the authors' request.
   Quality and efficiency metrics will be collected for each submission,
   and compiled on a ReQuEST live scoreboard similar 
   to this <a href="http://cKnowledge.org/repo">open optimization repository</a>.

   <p>
   ReQuEST will not determine a single winner, as collapsing all of the metrics into one single metric across all platforms 
   will result in over-engineered solutions.
   Instead, each ReQuEST tournament will expose a set of quality, performance and efficiency metrics
   to perform optimizations on.
   Solutions do not have to be on the Pareto frontier to be accepted for the associated ReQuEST workshops
   and the open ReQuEST repository - 
   a submission can be praised for its originality, reproducibility, 
   adaptability, scalability, portability, ease of use, etc. However, submissions on the Pareto frontier 
   will obtain a "Pareto-optimal" seal on their paper and be eligible for special prizes from industrial sponsors.
   Descriptions of the accepted workflows will be published in the <a href="http://dl.acm.org">ACM Digital Library</a> 
   along with reusable artifacts.
  </div>

</div>

<!---------------------------------------------------------------------------------------->
<a id="industrial_board"><h3>Industrial advisory board</h3>

<div style="margin-left:30px;">

 <i>To be announced - <a href="mailto:anton@dividiti.com">contact us</a> 
 if you are interested to join this board or know more!</i>

 <p>
 Members of the ReQuEST industrial advisory board suggest realistic workloads,
 collaborate on a common methodology for reproducible evaluation and optimization,
 arrange access to novel hardware to Artifact Evaluation Committee,
 and provide prizes for the most Pareto-optimal solutions.
</div>

<!---------------------------------------------------------------------------------------->
<a id="workshops"><h3>ReQuEST workshops</h3>

<div style="margin-left:30px;">
 We will use ReQuEST workshops associated with tournaments to let authors present 
 and discuss their most efficient algorithms. 
 We will also use workshops as an open forum to discuss 
 how to improve our common reproducible methodology and framework
 for SW/HW co-design of emerging workloads with a broad 
 academic and industrial community!
</div>

<br>
<br>
<center>
Feel free to <a href="mailto:moreau@cs.washington.edu;Grigori.Fursin@cTuning.org">contact us</a> if you have questions or suggestions!
</center>

<br>

Artificial Intelligence (AI), Machine Learning (ML) and other
emerging workloads demand efficient computer systems from the
cloud to the edge. Systems designers, however, face numerous
challenges from tackling the ever-growing space of design and
optimization choices (including algorithms, models, software
frameworks, libraries, hardware platforms, optimization
techniques) to balancing off multiple objectives (including
accuracy, speed, throughput, power, size, price). Furthermore,
the lack of a common experimental framework and methodology
makes it even more challenging to keep up with and build upon
the latest research advances.

The Reproducibly Quality-Efficient Systems Tournaments
(ReQuEST) initiative is a community effort to develop
a rigorous methodology, open platform and online scoreboard
for co-designing the efficient and reliable software/hardware
stack for emerging workloads. ReQuEST invites
a multidisciplinary community to collaborate on benchmarking
and optimizing workloads across diverse platforms, models,
data sets, libraries and tools, while gradually adopting best
practice. The community effectively creates a “marketplace”
for trading Pareto-efficient implementations (code and data)
as portable, customizable and reusable Collective Knowledge
workflows and packages. We envision that such
a community-driven and decentralized marketplace will help
accelerate adoption and technology transfer of novel AI/ML
techniques similar to the open-source movement.

Please see the front matter for the 1st ReQuEST tournament
on Co-designing Pareto-efficient Deep Learning Inference
at ASPLOS'18 to learn more about the shared workflows and
validated results, as well as about our next steps for the
ReQuEST initiative.
